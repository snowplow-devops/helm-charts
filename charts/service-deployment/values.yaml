global:
  # -- Cloud specific bindings (options: aws, gcp , azure)
  cloud: ""

  # global labels will be applied to all resources deployed by the chart
  labels: {}

# -- Overrides the full-name given to the deployment resources (default: .Release.Name)
fullnameOverride: ""

image:
  repository: "nginx"
  tag: "latest"
  # -- Whether the repository is public
  isRepositoryPublic: true
  # -- The image pullPolicy to use
  pullPolicy: "IfNotPresent"

config:
  command: []
  #  - "/bin/sh"
  args: []
  #  - "-c"
  #  - "echo 'Environment $(hello_env)! Secret $(username).'"

  # -- Map of environment variables to use within the job
  env:
  #  hello_env: "world"

  # -- Map of secrets that will be exposed as environment variables within the job
  secrets: {}
  #  username: "password"
  # -- Map of base64-encoded secrets that will be exposed as environment variables within the job
  secretsB64: {}
  #  username: "cGFzc3dvcmQK"

  # -- List of configMaps from other deployments within the
  #    same namespace - to reference and mount in the deployment
  sharedNamespaceConfigMaps: []
  #  - name: "10c8b-config-fs-dev1"
  #    mountPath: "/etc/config" # Must match the path of referenced volume
  #    mountPropagation: None # If unset will default to 'None'
  #    readOnly: true #  If unset will default to 'true'
  #  - name: "another-shared-configmap"
  #    mountPath: "/app/config" # Must match the path of referenced volume

# -- List of config maps to mount to the deployment
configMaps: []
#  - name: "volume-1"
#    mountPath: "/etc/config" # Must be unique
#    mountPropagation: None # If unset will default to 'None'
#    files: []
#      - key: "file.cfg" # Key must be unique for each file
#        contentsB64: "" # The file contents which have already been base-64 encoded
#        contentsFile: "" # The path to a local file (note: contentsB64 will take precedence if not-empty)

# -- Map of resource constraints for the service
resources: {}
#  limits:
#    cpu: 746m
#    memory: 900Mi
#  requests:
#    cpu: 400m
#    memory: 512Mi

# -- readinessProbe is enabled if httpGet.path or exec.command are present
readinessProbe:
  httpGet:
    # -- Path for health checks to be performed to determine readiness
    path: ""
  exec:
    # -- Command/arguments to execute to determine readiness
    command: []
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 2

# -- livenessProbe is enabled if httpGet.path or exec.command are present
livenessProbe:
  httpGet:
    # -- Path for health checks to be performed to determine liveness
    path: ""
    port: ""
  exec:
    # -- Command/arguments to execute to determine liveness
    command: []
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 1

# -- Grace period for termination of the service
terminationGracePeriodSeconds: 60

hpa:
  # -- Whether to deploy HPA rules
  deploy: true
  # -- Minimum number of pods to deploy
  minReplicas: 1
  # -- Maximum number of pods to deploy
  maxReplicas: 20
  # -- Default average CPU utilization before auto-scaling starts
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  behavior: {}

vpa:
  # -- Whether to deploy VPA rules
  enabled: false
  # -- VPA resource specification (accepts any valid VPA spec fields)
  spec: {}
  # Examples of common VPA configurations:
  #
  # Basic auto-scaling (recommended for most workloads):
  # spec:
  #   updatePolicy:
  #     updateMode: "Recreate"
  #   resourcePolicy:
  #     containerPolicies:
  #     - containerName: '*'
  #       minAllowed:
  #         cpu: 100m
  #         memory: 128Mi
  #       maxAllowed:
  #         cpu: 2
  #         memory: 4Gi
  #
  # Recommendation-only mode (for testing):
  # spec:
  #   updatePolicy:
  #     updateMode: "Off"
  #
  # Conservative scaling with controlled resources:
  # spec:
  #   updatePolicy:
  #     updateMode: "Recreate"
  #   resourcePolicy:
  #     containerPolicies:
  #     - containerName: '*'
  #       controlledResources: ["cpu", "memory"]
  #       controlledValues: "RequestsAndLimits"
  #       minAllowed:
  #         cpu: 100m
  #         memory: 128Mi
  #       maxAllowed:
  #         cpu: 1
  #         memory: 2Gi

service:
  # -- Whether to setup service bindings (note: only NodePort is supported)
  deploy: true
  # -- Port to bind and expose the service on
  port: 8000
  # -- The Target Port that the actual application is being exposed on
  targetPort: 80
  # -- Protocol that the service leverages (note: TCP or UDP)
  protocol: "TCP"
  aws:
    # -- EC2 TargetGroup ARN to bind the service onto
    targetGroupARN: ""
  gcp:
    # -- Name of the Network Endpoint Group to bind onto
    networkEndpointGroupName: ""
  # -- Map of annotations to add to the service
  annotations: {}
  # -- A map of ingress rules to deploy
  ingress:
    {}
    # ingress-0001:
    #   hostname: example-01.com
    # ingress-0002:
    #   hostname: example-02.com # -- Hostname to map Ingress to
    #   certificateCreate: false # -- Create a Certificate resource for this Ingress (default: true)
    #   certificateIssuerName: cloudflare # -- What issuer to use for the Certificate (default: letsencrypt-staging)
    #   certificateIssuerKind: Issuer # -- Kind of issuer (default: ClusterIssuer)
    #   enableTraefik: false # -- Enables traefik annotations and set ingressClassName. (default: true)
    #   tlsSecretName: qa1-tracking-snowplow-io-tls # -- Override TLS secret name (optional, defaults to {hostname}-tls)
    #   annotations: {} # -- Map of annotations to add to the ingress
  # -- List of IP addresses to restrict ingress traffic to
  ingressIPAllowlist: []

dockerconfigjson:
  # -- Name of the secret to use for the private repository
  name: "snowplow-sd-dockerhub"
  # -- Username for the private repository
  username: ""
  # -- Password for the private repository
  password: ""
  # -- Repository server URL
  server: "https://index.docker.io/v1/"
  # -- Email address for user of the private repository
  email: ""

cloudserviceaccount:
  # -- Whether to create a service-account
  deploy: false
  # -- Name of the service-account to create
  name: "snowplow-sd-service-account"
  aws:
    # -- IAM Role ARN to bind to the k8s service account
    roleARN: ""
  gcp:
    # -- Service Account email to bind to the k8s service account
    serviceAccount: ""
  azure:
    # -- Workload managed identity id to bind to the k8s service account
    managedIdentityId: ""

deployment:
  # -- Can be either a "Deployment" or "StatefulSet"
  kind: "Deployment"
  # deployment replica can only be set if hpa.enabled = false
  replicas: 1
  # -- When enabled, disables the HPA and scales the deployment to zero replicas
  scaleToZero: false
  # -- How to replace existing pods with new ones
  strategy:
    # -- Change to "Recreate" if all pods should be killed before new ones are created
    type: "RollingUpdate"
    rollingUpdate:
      # -- The max number or percent of pods that can be unavailable during rolling update. Can be set as number "3" for 3 pods unavailable
      maxUnavailable: "25%"
      # -- The maximum number or precent of pods that can be created in addition to the current number of pods during the rolling update. Can be set as number "5" for 5 additional pods
      maxSurge: "25%"
  # -- Map of labels that will be added to each pod in the deployment
  podLabels:
    {}
    # env: prod2
    # dept: engineering

# -- PriorityClassName for pods
priorityClassName: ""

# -- Allow the scheduler to schedule pods with matching taints
#
# more details here: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
tolerations: []

# -- topologySpreadConstraints control how Pods are  spread across your cluster among failure-domains such as regions, zones, nodes, and other user-defined topology domains.
#
# more details here: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
topologySpreadConstraints: {}

# -- Affinity supports podAffinity, podAntiAffinity, or nodeAffinity
affinity: {}
# podAffinity:
#    requiredDuringSchedulingIgnoredDuringExecution:
#    - labelSelector:
#        matchExpressions:
#        - key: security
#          operator: In
#          values:
#          - S1
#      topologyKey: topology.kubernetes.io/zone
# podAntiAffinity:
#   preferredDuringSchedulingIgnoredDuringExecution:
#   - weight: 100
#     podAffinityTerm:
#       labelSelector:
#         matchExpressions:
#         - key: app.kubernetes.io/name
#           operator: In
#           values:
#           - collector
#       topologyKey: topology.kubernetes.io/hostname
# nodeAffinity:
#    requiredDuringSchedulingIgnoredDuringExecution:
#      nodeSelectorTerms:
#      - matchExpressions:
#        - key: kubernetes.io/os
#          operator: In
#          values:
#          - linux

persistentVolume:
  # -- Whether to deploy a persistent-volume (note: when deployment.kind is "StatefulSet" one volume will be created per replica)
  enabled: false
  # -- Access modes to allow (note: this will impact HPA rules if the volume cannot be bound to all containers when deployment.kind is "Deployment")
  accessModes:
    - ReadWriteOnce
  # -- Sets the retention policies for the volumes created in "StatefulSet" mode
  statefulSetRetentionPolicy:
    # -- What to do with volumes when the StatefulSet is deleted
    whenDeleted: "Retain"
    # -- What to do with volumes when scaling occurs
    whenScaled: "Delete"
  # -- Persistent Volume labels
  labels: {}
  # -- Persistent Volume annotations
  annotations: {}
  # -- Persistent Volume mount root path
  mountPath: /data
  # -- Persistent Volume size
  size: 8Gi
  # -- Subdirectory of Persistent Volume to mount
  subPath: ""
  # -- Set to "-" or "" to disable dynamic provisioning, if undefined uses the default provisioner
  # storageClass: "-"


# Hooks Configuration
hooks:
  {}
  # Example: Database Bootstrap Hook
  # db-bootstrap:
  #   # -- Whether to enable this hook
  #   enabled: false
  #   # -- Container image to use for the hook
  #   image: postgres:alpine
  #   # -- When to run the hook (pre-install, post-install, pre-upgrade, post-upgrade, pre-delete, post-delete, pre-rollback, post-rollback)
  #   hookPhase: "pre-install"
  #   # -- Hook deletion policy (hook-succeeded, hook-failed, before-hook-creation)
  #   hookDeletePolicy: "before-hook-creation,hook-succeeded"
  #   # -- Hook weight for execution order (lower numbers run first)
  #   hookWeight: 2
  #   # -- Maximum number of retries before marking job as failed
  #   backoffLimit: 3
  #   # -- Maximum time in seconds for the job to run
  #   activeDeadlineSeconds: 300
  #   # -- Time in seconds after job completion before cleanup (default: 86400 = 24 hours)
  #   ttlSecondsAfterFinished: 86400
  #   # -- Script to execute in the hook job
  #   script: |
  #     echo "Starting database bootstrap..."
  #     # Your bootstrap logic here
  #     echo "Bootstrap completed!"
  #   # -- Optional: Custom command to override default /bin/sh -c
  #   command: []
  #   # -- Optional: Custom args (if not using script)
  #   args: []
  #   # -- Environment variables specific to this hook
  #   env:
  #     HOOK_TYPE: "bootstrap"
  #   # -- Secrets specific to this hook
  #   secrets:
  #     DB_ADMIN_PASSWORD: "your-admin-password"
  #     DB_HOST: "your-db-host"
  #   # -- Configuration files to mount in the hook container
  #   configFiles:
  #     - name: "01-create-schema.sql"
  #       content: |
  #         CREATE SCHEMA IF NOT EXISTS myschema;
  #     - name: "02-create-tables.sql"
  #       content: |
  #         CREATE TABLE IF NOT EXISTS myschema.mytable (
  #           id SERIAL PRIMARY KEY,
  #           name VARCHAR(255)
  #         );
  #   # -- Path where config files will be mounted (default: /hook-config)
  #   configMountPath: "/bootstrap-sql"
  #   # -- Resource limits for the hook job
  #   resources:
  #     limits:
  #       cpu: 200m
  #       memory: 256Mi
  #     requests:
  #       cpu: 100m
  #       memory: 128Mi
  #   # -- Additional volumes to mount
  #   volumes: []
  #   # -- Additional volume mounts
  #   volumeMounts: []
  #
  # Example: Database Cleanup Hook
  # db-cleanup:
  #   enabled: false
  #   image: postgres:alpine
  #   hookPhase: "post-delete"
  #   hookDeletePolicy: "hook-succeeded"
  #   hookWeight: 1
  #   script: |
  #     echo "Starting database cleanup..."
  #     # Your cleanup logic here
  #     echo "Cleanup completed!"
  #   secrets:
  #     DB_ADMIN_PASSWORD: "your-admin-password"
  #     DB_HOST: "your-db-host"

# -- Extra Kubernetes objects to deploy alongside the service
# This allows for additional resources like Middleware, NetworkPolicy, etc.
extraObjects: []
